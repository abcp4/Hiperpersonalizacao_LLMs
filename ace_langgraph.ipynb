{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616291e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75f072",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e29be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langgraph langchain langchain-ollama langchain-core sentence-transformers faiss-cpu numpy rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6dde99",
   "metadata": {},
   "source": [
    "## Load Conversation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795628c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "locomo10_path = \"data/locomo/locomo10.json\"\n",
    "with open(locomo10_path, \"r\") as f:\n",
    "    locomo10 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d690cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation length: 58109 characters\n",
      "Number of questions: 199\n"
     ]
    }
   ],
   "source": [
    "def get_conversation_text(conversation):\n",
    "    text = \"\"\n",
    "    for key in conversation:\n",
    "        if key.startswith(\"session_\") and not key.endswith(\"_time\"):\n",
    "            session = conversation[key]\n",
    "            for msg_dict in session:\n",
    "                role = msg_dict['text']\n",
    "                text += role + \"\\n\"\n",
    "    return text\n",
    "\n",
    "conversation = get_conversation_text(locomo10[0]['conversation'])\n",
    "queries = locomo10[0]['qa']\n",
    "print(f\"Conversation length: {len(conversation)} characters\")\n",
    "print(f\"Number of questions: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218c96d",
   "metadata": {},
   "source": [
    "## Playbook Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991d2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Bullet:\n",
    "    \"\"\"Represents a bullet in the playbook with metadata\"\"\"\n",
    "    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    content: str = \"\"\n",
    "    helpful_count: int = 0\n",
    "    harmful_count: int = 0\n",
    "    \n",
    "    def mark_helpful(self):\n",
    "        self.helpful_count += 1\n",
    "    \n",
    "    def mark_harmful(self):\n",
    "        self.harmful_count += 1\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'id': self.id,\n",
    "            'content': self.content,\n",
    "            'helpful_count': self.helpful_count,\n",
    "            'harmful_count': self.harmful_count\n",
    "        }\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[ID: {self.id[:8]}] {self.content} (✓{self.helpful_count}/✗{self.harmful_count})\"\n",
    "\n",
    "class Playbook:\n",
    "    \"\"\"Manages the collection of bullets, user profiles, and memories/events\"\"\"\n",
    "    def __init__(self):\n",
    "        self.bullets: List[Bullet] = []\n",
    "        self.user_profiles: Dict[str, Any] = {}\n",
    "        self.memories_events: List[Dict[str, Any]] = []\n",
    "    \n",
    "    def add_bullet(self, bullet: Bullet):\n",
    "        self.bullets.append(bullet)\n",
    "    \n",
    "    def update_bullet(self, index: int, new_content: str):\n",
    "        if 0 <= index < len(self.bullets):\n",
    "            self.bullets[index].content = new_content\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def remove_bullet(self, index: int):\n",
    "        if 0 <= index < len(self.bullets):\n",
    "            self.bullets.pop(index)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def modify_user_profile(self, user_id: str, profile_data: Dict[str, Any]):\n",
    "        if user_id in self.user_profiles:\n",
    "            self.user_profiles[user_id].update(profile_data)\n",
    "        else:\n",
    "            self.user_profiles[user_id] = profile_data\n",
    "    \n",
    "    def add_memory_event(self, event_data: Dict[str, Any]):\n",
    "        self.memories_events.append(event_data)\n",
    "    \n",
    "    def update_memory_event(self, index: int, new_event_data: Dict[str, Any]):\n",
    "        if 0 <= index < len(self.memories_events):\n",
    "            self.memories_events[index] = new_event_data\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def format_for_prompt(self) -> str:\n",
    "        if not self.bullets and not self.user_profiles and not self.memories_events:\n",
    "            return \"No previous knowledge available\"\n",
    "        \n",
    "        formatted_output = []\n",
    "        \n",
    "        if self.bullets:\n",
    "            formatted_output.append(\"Knowledge Bullets:\")\n",
    "            for i, bullet in enumerate(self.bullets):\n",
    "                formatted_output.append(f\"{i}. {bullet}\")\n",
    "        \n",
    "        if self.user_profiles:\n",
    "            formatted_output.append(\"\\nUser Profiles:\")\n",
    "            for user_id, profile in self.user_profiles.items():\n",
    "                formatted_output.append(f\"User {user_id}: {profile}\")\n",
    "        \n",
    "        if self.memories_events:\n",
    "            formatted_output.append(\"\\nMemories and Events:\")\n",
    "            for i, event in enumerate(self.memories_events):\n",
    "                formatted_output.append(f\"{i}. {event}\")\n",
    "        \n",
    "        return \"\\n\".join(formatted_output)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.bullets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f91c0",
   "metadata": {},
   "source": [
    "## Retrieval Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db000e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spike/miniforge3/envs/nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking conversation with chunk_size=500...\n",
      "Created 141 chunks\n",
      "Embedding chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:00<00:00, 21.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FAISS index...\n",
      "✓ Retrieval engine ready with 141 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from typing import List, Tuple\n",
    "\n",
    "class ConversationRetriever:\n",
    "    \"\"\"Retrieval engine for finding relevant conversation chunks\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2', chunk_size: int = 500):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunks: List[str] = []\n",
    "        self.embeddings: np.ndarray = None\n",
    "        self.index = None\n",
    "        \n",
    "    def chunk_conversation(self, conversation_text: str, overlap: int = 50) -> List[str]:\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        text_len = len(conversation_text)\n",
    "        \n",
    "        while start < text_len:\n",
    "            end = min(start + self.chunk_size, text_len)\n",
    "            chunk = conversation_text[start:end]\n",
    "            \n",
    "            if end < text_len:\n",
    "                last_period = chunk.rfind('.')\n",
    "                last_newline = chunk.rfind('\\n')\n",
    "                break_point = max(last_period, last_newline)\n",
    "                \n",
    "                if break_point > self.chunk_size * 0.5:\n",
    "                    chunk = chunk[:break_point + 1]\n",
    "                    end = start + break_point + 1\n",
    "            \n",
    "            chunks.append(chunk.strip())\n",
    "            start = end - overlap if end < text_len else end\n",
    "            \n",
    "        return chunks\n",
    "    \n",
    "    def embed_conversation(self, conversation_text: str):\n",
    "        print(f\"Chunking conversation with chunk_size={self.chunk_size}...\")\n",
    "        self.chunks = self.chunk_conversation(conversation_text)\n",
    "        print(f\"Created {len(self.chunks)} chunks\")\n",
    "        \n",
    "        print(\"Embedding chunks...\")\n",
    "        self.embeddings = self.model.encode(self.chunks, show_progress_bar=True)\n",
    "        \n",
    "        print(\"Building FAISS index...\")\n",
    "        dimension = self.embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.index.add(self.embeddings.astype('float32'))\n",
    "        \n",
    "        print(f\"✓ Retrieval engine ready with {len(self.chunks)} chunks\")\n",
    "    \n",
    "    def get_context(self, query: str, top_k: int = 3, separator: str = \"\\n\\n---\\n\\n\") -> str:\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"No conversation embedded. Call embed_conversation() first.\")\n",
    "        \n",
    "        query_embedding = self.model.encode([query])\n",
    "        distances, indices = self.index.search(query_embedding.astype('float32'), top_k)\n",
    "        \n",
    "        chunks = [self.chunks[idx] for idx in indices[0] if idx < len(self.chunks)]\n",
    "        return separator.join(chunks)\n",
    "\n",
    "# Initialize global retriever\n",
    "retriever = ConversationRetriever(chunk_size=500)\n",
    "retriever.embed_conversation(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ec7d6",
   "metadata": {},
   "source": [
    "## LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd983558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:27b-it-qat\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1654963",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868f8a9",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ed4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Prompt\n",
    "generator_prompt = \"\"\"\n",
    "I am your supervisor and you are a super intelligent AI Assistant whose job is to achieve my day-to-day tasks completely autonomously.\n",
    "You will be given a cheatsheet containing relevant strategies, patterns, and examples from similar problems to apply and solve the\n",
    "current task.\n",
    "Cheatsheet:\n",
    "{playbook_text}\n",
    "\n",
    "Context of the Conversation:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "1. ANALYSIS & STRATEGY\n",
    "Carefully analyze both the question and cheatsheet before starting\n",
    "Search for and identify any applicable patterns, strategies, or examples within the cheatsheet\n",
    "Create a structured approach to solving the problem at hand\n",
    "Review and document any limitations in the provided reference materials\n",
    "2. SOLUTION DEVELOPMENT\n",
    "Present your solution using clear, logical steps that others can follow and review\n",
    "Explain your reasoning and methodology before presenting final conclusions\n",
    "Provide detailed explanations for each step of the process\n",
    "Check and verify all assumptions and intermediate calculations\n",
    "\n",
    "\n",
    "Answer: [your answer here]\n",
    "Reasoning: [your detailed reasoning here]\n",
    "Key Insights: [list of key insights derived from the cheatsheet and context]\n",
    "\"\"\"\n",
    "\n",
    "# Reflector Prompt\n",
    "reflector_prompt = \"\"\" You are an expert in extracting insights from conversation interactions.\n",
    "Context of the Conversation:\n",
    "{context}\n",
    "Generated Answer: {generated_answer}\n",
    "Current Playbook:\n",
    "{playbook_text}\n",
    "Analyze the generated answer and reasoning process and identify from a global perspective:\n",
    "1. Strategies that worked well in generating the answer\n",
    "2. Important domain concepts that were helpful\n",
    "3. Patterns in the context that aided in answering\n",
    "4. Knowledge that would be useful for similar future questions\n",
    "Also, identify the user profile information:\n",
    "1. Relevant user preferences or traits revealed in the conversation\n",
    "2. Behavioral patterns that could inform future interactions\n",
    "3. Any specific needs or goals indicated by the user\n",
    "Finally, extract any memories or events from the conversation that could be relevant to improving the playbook\n",
    "\n",
    "Write the 3 sections in the following format:\n",
    "INSIGHTS:\n",
    "1. [insight 1]\n",
    "2. [insight 2]\n",
    "...\n",
    "\n",
    "USER_PROFILE:\n",
    "1. [profile item 1]\n",
    "2. [profile item 2]\n",
    "...\n",
    "\n",
    "MEMORIES_EVENTS:\n",
    "1. [memory/event 1]\n",
    "2. [memory/event 2]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# Insights Curator Prompt\n",
    "insights_curator_prompt = \"\"\"You are an insights knowledge curator. Your task is to evaluate insights and decide what to add, update, or remove from the playbook's knowledge bullets.\n",
    "\n",
    "Current Playbook Bullets:\n",
    "{playbook_bullets}\n",
    "\n",
    "Original Question: {query}\n",
    "Generated Answer: {generated_answer}\n",
    "\n",
    "Proposed Insights:\n",
    "{insights_text}\n",
    "\n",
    "Evaluate each insight carefully and decide:\n",
    "1. Whether the insight should be ADDED as a new bullet (is it useful, relevant, and non-redundant)\n",
    "2. Whether the insight should UPDATE an existing bullet (if it refines or corrects existing knowledge)\n",
    "3. Whether existing bullets should be REMOVED (if they are outdated or incorrect)\n",
    "\n",
    "IMPORTANT: Avoid redundancy! If a new insight is similar to an existing bullet, prefer to UPDATE the existing one rather than adding a duplicate.\n",
    "\n",
    "Answer in the format:\n",
    "ADD_INSIGHTS: [list the numbers of insights to add as new bullets, separated by commas, or 'none']\n",
    "UPDATE_INSIGHTS: [format: \"insight_number->bullet_index\" to update existing bullet, separated by commas, or 'none']\n",
    "REMOVE_BULLETS: [list the bullet indices to remove, separated by commas, or 'none']\n",
    "REASON: [brief explanation of your decisions, especially for updates and removals]\n",
    "\"\"\"\n",
    "\n",
    "# User Profile Curator Prompt\n",
    "user_profile_curator_prompt = \"\"\"You are a user profile curator. Your task is to evaluate user profile information and decide what to add or update in the playbook.\n",
    "\n",
    "Current User Profiles:\n",
    "{user_profiles}\n",
    "\n",
    "Original Question: {query}\n",
    "Generated Answer: {generated_answer}\n",
    "\n",
    "Proposed User Profile Items:\n",
    "{user_profile_text}\n",
    "\n",
    "Evaluate each user profile item carefully and decide:\n",
    "1. Whether the item should be ADDED as new user profile information\n",
    "2. Whether the item should UPDATE existing user profile information\n",
    "\n",
    "Answer in the format:\n",
    "ADD_USER_PROFILE: [list the numbers of user profile items to add, separated by commas, or 'none']\n",
    "UPDATE_USER_PROFILE: [list the numbers of user profile items to update, separated by commas, or 'none']\n",
    "REASON: [brief explanation of your decisions]\n",
    "\"\"\"\n",
    "\n",
    "# Memories Curator Prompt\n",
    "memories_curator_prompt = \"\"\"You are a memories and events curator. Your task is to evaluate memories and events extracted from conversations and decide what to add or update in the playbook.\n",
    "\n",
    "Current Memories and Events:\n",
    "{memories_events}\n",
    "\n",
    "Original Question: {query}\n",
    "Generated Answer: {generated_answer}\n",
    "\n",
    "Proposed Memories/Events:\n",
    "{memories_events_text}\n",
    "\n",
    "Evaluate each memory/event carefully and decide:\n",
    "1. Whether the memory/event should be ADDED as new information\n",
    "2. Whether the memory/event should UPDATE existing memory/event information\n",
    "\n",
    "Answer in the format:\n",
    "ADD_MEMORIES_EVENTS: [list the numbers of memories/events to add, separated by commas, or 'none']\n",
    "UPDATE_MEMORIES_EVENTS: [format: \"memory_number->event_index\" to update existing event, separated by commas, or 'none']\n",
    "REASON: [brief explanation of your decisions]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376fff8",
   "metadata": {},
   "source": [
    "### Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7ec513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Prompt - Portuguese\n",
    "generator_prompt = \"\"\"\n",
    "Eu sou seu supervisor e você é um Assistente de IA super inteligente cujo trabalho é realizar minhas tarefas do dia a dia de forma completamente autônoma.\n",
    "Você receberá uma folha de dicas contendo estratégias relevantes, padrões e exemplos de problemas similares para aplicar e resolver a\n",
    "tarefa atual.\n",
    "Playbook:\n",
    "{playbook_text}\n",
    "\n",
    "Contexto da Conversa:\n",
    "{context}\n",
    "\n",
    "Instruções:\n",
    "1. ANÁLISE & ESTRATÉGIA\n",
    "Analise cuidadosamente tanto a pergunta quanto a folha de dicas antes de começar\n",
    "Busque e identifique quaisquer padrões, estratégias ou exemplos aplicáveis dentro da folha de dicas\n",
    "Crie uma abordagem estruturada para resolver o problema em questão\n",
    "Revise e documente quaisquer limitações nos materiais de referência fornecidos\n",
    "2. DESENVOLVIMENTO DA SOLUÇÃO\n",
    "Apresente sua solução usando passos claros e lógicos que outros possam seguir e revisar\n",
    "Explique seu raciocínio e metodologia antes de apresentar conclusões finais\n",
    "Forneça explicações detalhadas para cada etapa do processo\n",
    "Verifique e valide todas as suposições e cálculos intermediários\n",
    "\n",
    "\n",
    "Resposta: [sua resposta aqui]\n",
    "Raciocínio: [seu raciocínio detalhado aqui]\n",
    "Insights Chave: [lista de insights chave derivados da folha de dicas e contexto]\n",
    "\"\"\"\n",
    "\n",
    "# Reflector Prompt - Portuguese\n",
    "reflector_prompt = \"\"\"Você é um especialista em extrair insights de interações de conversa.\n",
    "Contexto da Conversa:\n",
    "{context}\n",
    "Resposta Gerada: {generated_answer}\n",
    "Playbook Atual:\n",
    "{playbook_text}\n",
    "Analise a resposta gerada e o processo de raciocínio e identifique de uma perspectiva global:\n",
    "1. Estratégias que funcionaram bem na geração da resposta\n",
    "2. Conceitos de domínio importantes que foram úteis\n",
    "3. Padrões no contexto que auxiliaram na resposta\n",
    "4. Conhecimento que seria útil para perguntas futuras similares\n",
    "Além disso, identifique as informações do perfil do usuário:\n",
    "1. Preferências ou características relevantes do usuário reveladas na conversa\n",
    "2. Padrões comportamentais que poderiam informar interações futuras\n",
    "3. Quaisquer necessidades ou objetivos específicos indicados pelo usuário\n",
    "Finalmente, extraia quaisquer memórias ou eventos da conversa que possam ser relevantes para melhorar o playbook\n",
    "\n",
    "Escreva as 3 seções no seguinte formato:\n",
    "INSIGHTS:\n",
    "1. [insight 1]\n",
    "2. [insight 2]\n",
    "...\n",
    "\n",
    "USER_PROFILE:\n",
    "1. [item do perfil 1]\n",
    "2. [item do perfil 2]\n",
    "...\n",
    "\n",
    "MEMORIES_EVENTS:\n",
    "1. [memória/evento 1]\n",
    "2. [memória/evento 2]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# Insights Curator Prompt - Portuguese\n",
    "insights_curator_prompt = \"\"\"Você é um curador de conhecimento de insights. Sua tarefa é avaliar insights e decidir o que adicionar, atualizar ou remover dos bullets de conhecimento do playbook.\n",
    "\n",
    "Bullets Atuais do Playbook:\n",
    "{playbook_bullets}\n",
    "\n",
    "Pergunta Original: {query}\n",
    "Resposta Gerada: {generated_answer}\n",
    "\n",
    "Insights Propostos:\n",
    "{insights_text}\n",
    "\n",
    "Avalie cada insight cuidadosamente e decida:\n",
    "1. Se o insight deve ser ADICIONADO como um novo bullet (é útil, relevante e não redundante)\n",
    "2. Se o insight deve ATUALIZAR um bullet existente (se refina ou corrige conhecimento existente)\n",
    "3. Se bullets existentes devem ser REMOVIDOS (se estão desatualizados ou incorretos)\n",
    "\n",
    "IMPORTANTE: Evite redundância! Se um novo insight é similar a um bullet existente, prefira ATUALIZAR o existente em vez de adicionar um duplicado.\n",
    "\n",
    "Responda no formato:\n",
    "ADD_INSIGHTS: [liste os números dos insights a adicionar como novos bullets, separados por vírgulas, ou 'none']\n",
    "UPDATE_INSIGHTS: [formato: \"número_insight->índice_bullet\" para atualizar bullet existente, separados por vírgulas, ou 'none']\n",
    "REMOVE_BULLETS: [liste os índices dos bullets a remover, separados por vírgulas, ou 'none']\n",
    "REASON: [breve explicação de suas decisões, especialmente para atualizações e remoções]\n",
    "\"\"\"\n",
    "\n",
    "# User Profile Curator Prompt - Portuguese\n",
    "user_profile_curator_prompt = \"\"\"Você é um curador de perfis de usuário. Sua tarefa é avaliar informações de perfil de usuário e decidir o que adicionar ou atualizar no playbook.\n",
    "\n",
    "Perfis de Usuário Atuais:\n",
    "{user_profiles}\n",
    "\n",
    "Pergunta Original: {query}\n",
    "Resposta Gerada: {generated_answer}\n",
    "\n",
    "Itens de Perfil de Usuário Propostos:\n",
    "{user_profile_text}\n",
    "\n",
    "Avalie cada item de perfil de usuário cuidadosamente e decida:\n",
    "1. Se o item deve ser ADICIONADO como nova informação de perfil de usuário\n",
    "2. Se o item deve ATUALIZAR informações existentes de perfil de usuário\n",
    "\n",
    "Responda no formato:\n",
    "ADD_USER_PROFILE: [liste os números dos itens de perfil de usuário a adicionar, separados por vírgulas, ou 'none']\n",
    "UPDATE_USER_PROFILE: [liste os números dos itens de perfil de usuário a atualizar, separados por vírgulas, ou 'none']\n",
    "REASON: [breve explicação de suas decisões]\n",
    "\"\"\"\n",
    "\n",
    "# Memories Curator Prompt - Portuguese\n",
    "memories_curator_prompt = \"\"\"Você é um curador de memórias e eventos. Sua tarefa é avaliar memórias e eventos extraídos de conversas e decidir o que adicionar ou atualizar no playbook.\n",
    "\n",
    "Memórias e Eventos Atuais:\n",
    "{memories_events}\n",
    "\n",
    "Pergunta Original: {query}\n",
    "Resposta Gerada: {generated_answer}\n",
    "\n",
    "Memórias/Eventos Propostos:\n",
    "{memories_events_text}\n",
    "\n",
    "Avalie cada memória/evento cuidadosamente e decida:\n",
    "1. Se a memória/evento deve ser ADICIONADA como nova informação\n",
    "2. Se a memória/evento deve ATUALIZAR informações existentes de memória/evento\n",
    "\n",
    "Responda no formato:\n",
    "ADD_MEMORIES_EVENTS: [liste os números das memórias/eventos a adicionar, separados por vírgulas, ou 'none']\n",
    "UPDATE_MEMORIES_EVENTS: [formato: \"memory_number->event_index\" para atualizar evento existente, separados por vírgulas, ou 'none']\n",
    "REASON: [breve explicação de suas decisões]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b352b",
   "metadata": {},
   "source": [
    "## LangGraph State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fdc9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "import operator\n",
    "\n",
    "class ACEState(TypedDict):\n",
    "    \"\"\"State for the ACE workflow\"\"\"\n",
    "    # Input\n",
    "    question: str\n",
    "    playbook: Playbook\n",
    "    top_k: int\n",
    "    \n",
    "    # Retrieved context\n",
    "    context: str\n",
    "    \n",
    "    # Generator output\n",
    "    generated_answer: str\n",
    "    \n",
    "    # Reflector output\n",
    "    reflector_answer: str\n",
    "    sections: Dict[str, List[str]]\n",
    "    \n",
    "    # Curator outputs\n",
    "    insights_curator_answer: str\n",
    "    user_profile_curator_answer: str\n",
    "    memories_curator_answer: str\n",
    "    curator_answer: str\n",
    "    \n",
    "    # Parsed actions\n",
    "    actions: Dict[str, Any]\n",
    "    \n",
    "    # Tracking\n",
    "    messages: Annotated[List[str], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15e00f",
   "metadata": {},
   "source": [
    "## Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b609ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def retrieve_context_node(state: ACEState) -> ACEState:\n",
    "    \"\"\"Node: Retrieve relevant conversation context\"\"\"\n",
    "    context = retriever.get_context(state[\"question\"], top_k=state[\"top_k\"])\n",
    "    state[\"context\"] = context\n",
    "    state[\"messages\"].append(f\"✓ Retrieved context ({len(context)} chars)\")\n",
    "    return state\n",
    "\n",
    "def generate_answer_node(state: ACEState) -> ACEState:\n",
    "    \"\"\"Node: Generate answer using current playbook\"\"\"\n",
    "    template = ChatPromptTemplate([\n",
    "        (\"system\", generator_prompt),\n",
    "        (\"user\", \"{query}\"),\n",
    "    ])\n",
    "    \n",
    "    chain = template | llm | StrOutputParser()\n",
    "    \n",
    "    answer = chain.invoke({\n",
    "        \"playbook_text\": state[\"playbook\"].format_for_prompt(),\n",
    "        \"context\": state[\"context\"],\n",
    "        \"query\": state[\"question\"],\n",
    "    })\n",
    "    \n",
    "    state[\"generated_answer\"] = f\"Question: {state['question']}\\n\\n{answer}\"\n",
    "    state[\"messages\"].append(f\"✓ Generated answer ({len(answer)} chars)\")\n",
    "    return state\n",
    "\n",
    "def reflect_on_answer_node(state: ACEState) -> ACEState:\n",
    "    \"\"\"Node: Reflect on the generated answer\"\"\"\n",
    "    template = ChatPromptTemplate([\n",
    "        (\"system\", reflector_prompt),\n",
    "        (\"user\", \"{query}\"),\n",
    "    ])\n",
    "    \n",
    "    chain = template | llm | StrOutputParser()\n",
    "    \n",
    "    reflector_output = chain.invoke({\n",
    "        \"playbook_text\": state[\"playbook\"].format_for_prompt(),\n",
    "        \"context\": state[\"context\"],\n",
    "        \"generated_answer\": state[\"generated_answer\"],\n",
    "        \"query\": \"Extract useful insights to improve the playbook.\",\n",
    "    })\n",
    "    \n",
    "    state[\"reflector_answer\"] = reflector_output\n",
    "    state[\"messages\"].append(\"✓ Reflection complete\")\n",
    "    return state\n",
    "\n",
    "def parse_sections_node(state: ACEState) -> ACEState:\n",
    "    \"\"\"Node: Parse reflector output into sections\"\"\"\n",
    "    sections = {\"INSIGHTS\": [], \"USER_PROFILE\": [], \"MEMORIES_EVENTS\": []}\n",
    "    current_section = None\n",
    "    \n",
    "    for line in state[\"reflector_answer\"].splitlines():\n",
    "        line_stripped = line.strip()\n",
    "        line_upper = line_stripped.upper()\n",
    "        \n",
    "        if \"INSIGHT\" in line_upper and \":\" in line_stripped:\n",
    "            current_section = \"INSIGHTS\"\n",
    "            continue\n",
    "        elif \"USER\" in line_upper and \"PROFILE\" in line_upper and \":\" in line_stripped:\n",
    "            current_section = \"USER_PROFILE\"\n",
    "            continue\n",
    "        elif \"MEMOR\" in line_upper and \"EVENT\" in line_upper and \":\" in line_stripped:\n",
    "            current_section = \"MEMORIES_EVENTS\"\n",
    "            continue\n",
    "        \n",
    "        if line_stripped and current_section:\n",
    "            clean_line = re.sub(r'^[\\d\\-\\*]+[\\.\\)]\\s*', '', line_stripped).strip()\n",
    "            if clean_line and not clean_line.endswith(':'):\n",
    "                sections[current_section].append(clean_line)\n",
    "    \n",
    "    state[\"sections\"] = sections\n",
    "    state[\"messages\"].append(\n",
    "        f\"✓ Parsed sections: {len(sections['INSIGHTS'])} insights, \"\n",
    "        f\"{len(sections['USER_PROFILE'])} profiles, {len(sections['MEMORIES_EVENTS'])} events\"\n",
    "    )\n",
    "    return state\n",
    "\n",
    "def run_curators_node(state: ACEState) -> ACEState:\n",
    "    \"\"\"Node: Run all three curators\"\"\"\n",
    "    def format_section_list(items, section_name):\n",
    "        if not items:\n",
    "            return f\"No {section_name} available.\"\n",
    "        return \"\\n\".join([f\"{i+1}. {item}\" for i, item in enumerate(items)])\n",
    "    \n",
    "    sections = state[\"sections\"]\n",
    "    playbook = state[\"playbook\"]\n",
    "    \n",
    "    # Insights curator\n",
    "    insights_template = ChatPromptTemplate([(\"system\", insights_curator_prompt), (\"user\", \"{query}\")])\n",
    "    insights_chain = insights_template | llm | StrOutputParser()\n",
    "    \n",
    "    insights_answer = insights_chain.invoke({\n",
    "        \"playbook_bullets\": \"\\n\".join([f\"{i}. {bullet}\" for i, bullet in enumerate(playbook.bullets)]) if playbook.bullets else \"No bullets yet.\",\n",
    "        \"query\": state[\"question\"],\n",
    "        \"generated_answer\": state[\"generated_answer\"],\n",
    "        \"insights_text\": format_section_list(sections[\"INSIGHTS\"], \"insights\"),\n",
    "    })\n",
    "    \n",
    "    # User profile curator\n",
    "    profile_template = ChatPromptTemplate([(\"system\", user_profile_curator_prompt), (\"user\", \"{query}\")])\n",
    "    profile_chain = profile_template | llm | StrOutputParser()\n",
    "    \n",
    "    profile_answer = profile_chain.invoke({\n",
    "        \"user_profiles\": str(playbook.user_profiles) if playbook.user_profiles else \"No user profiles yet.\",\n",
    "        \"query\": state[\"question\"],\n",
    "        \"generated_answer\": state[\"generated_answer\"],\n",
    "        \"user_profile_text\": format_section_list(sections[\"USER_PROFILE\"], \"user profile items\"),\n",
    "    })\n",
    "    \n",
    "    # Memories curator\n",
    "    memories_template = ChatPromptTemplate([(\"system\", memories_curator_prompt), (\"user\", \"{query}\")])\n",
    "    memories_chain = memories_template | llm | StrOutputParser()\n",
    "    \n",
    "    memories_answer = memories_chain.invoke({\n",
    "        \"memories_events\": \"\\n\".join([f\"{i}. {event}\" for i, event in enumerate(playbook.memories_events)]) if playbook.memories_events else \"No memories/events yet.\",\n",
    "        \"query\": state[\"question\"],\n",
    "        \"generated_answer\": state[\"generated_answer\"],\n",
    "        \"memories_events_text\": format_section_list(sections[\"MEMORIES_EVENTS\"], \"memories/events\"),\n",
    "    })\n",
    "    \n",
    "    state[\"insights_curator_answer\"] = insights_answer\n",
    "    state[\"user_profile_curator_answer\"] = profile_answer\n",
    "    state[\"memories_curator_answer\"] = memories_answer\n",
    "    state[\"curator_answer\"] = f\"{insights_answer}\\n{profile_answer}\\n{memories_answer}\"\n",
    "    state[\"messages\"].append(\"✓ All curators completed\")\n",
    "    return state\n",
    "\n",
    "def parse_actions_node(state: ACEState) -> ACEState:\n",
    "    \"\"\"Node: Parse curator actions\"\"\"\n",
    "    actions = {\n",
    "        'insights_to_add': [],\n",
    "        'insights_to_update': {},\n",
    "        'bullets_to_remove': [],\n",
    "        'user_profiles_to_add': [],\n",
    "        'user_profiles_to_update': [],\n",
    "        'memories_events_to_add': [],\n",
    "        'memories_events_to_update': {}\n",
    "    }\n",
    "    \n",
    "    for line in state[\"curator_answer\"].splitlines():\n",
    "        line = line.strip()\n",
    "        \n",
    "        if line.startswith(\"ADD_INSIGHTS:\"):\n",
    "            add_part = line[len(\"ADD_INSIGHTS:\"):].strip()\n",
    "            if add_part.lower() != \"none\":\n",
    "                actions['insights_to_add'] = [int(x.strip()) for x in add_part.split(\",\") if x.strip().isdigit()]\n",
    "        \n",
    "        elif line.startswith(\"UPDATE_INSIGHTS:\"):\n",
    "            update_part = line[len(\"UPDATE_INSIGHTS:\"):].strip()\n",
    "            if update_part.lower() != \"none\":\n",
    "                for item in update_part.split(\",\"):\n",
    "                    if \"->\" in item:\n",
    "                        parts = item.split(\"->\")\n",
    "                        if len(parts) == 2 and parts[0].strip().isdigit() and parts[1].strip().isdigit():\n",
    "                            actions['insights_to_update'][int(parts[0].strip())] = int(parts[1].strip())\n",
    "        \n",
    "        elif line.startswith(\"REMOVE_BULLETS:\"):\n",
    "            remove_part = line[len(\"REMOVE_BULLETS:\"):].strip()\n",
    "            if remove_part.lower() != \"none\":\n",
    "                actions['bullets_to_remove'] = [int(x.strip()) for x in remove_part.split(\",\") if x.strip().isdigit()]\n",
    "        \n",
    "        elif line.startswith(\"ADD_USER_PROFILE:\"):\n",
    "            add_part = line[len(\"ADD_USER_PROFILE:\"):].strip()\n",
    "            if add_part.lower() != \"none\":\n",
    "                actions['user_profiles_to_add'] = [int(x.strip()) for x in add_part.split(\",\") if x.strip().isdigit()]\n",
    "        \n",
    "        elif line.startswith(\"UPDATE_USER_PROFILE:\"):\n",
    "            update_part = line[len(\"UPDATE_USER_PROFILE:\"):].strip()\n",
    "            if update_part.lower() != \"none\":\n",
    "                actions['user_profiles_to_update'] = [int(x.strip()) for x in update_part.split(\",\") if x.strip().isdigit()]\n",
    "        \n",
    "        elif line.startswith(\"ADD_MEMORIES_EVENTS:\"):\n",
    "            add_part = line[len(\"ADD_MEMORIES_EVENTS:\"):].strip()\n",
    "            if add_part.lower() != \"none\":\n",
    "                actions['memories_events_to_add'] = [int(x.strip()) for x in add_part.split(\",\") if x.strip().isdigit()]\n",
    "        \n",
    "        elif line.startswith(\"UPDATE_MEMORIES_EVENTS:\"):\n",
    "            update_part = line[len(\"UPDATE_MEMORIES_EVENTS:\"):].strip()\n",
    "            if update_part.lower() != \"none\":\n",
    "                for item in update_part.split(\",\"):\n",
    "                    if \"->\" in item:\n",
    "                        parts = item.split(\"->\")\n",
    "                        if len(parts) == 2 and parts[0].strip().isdigit() and parts[1].strip().isdigit():\n",
    "                            actions['memories_events_to_update'][int(parts[0].strip())] = int(parts[1].strip())\n",
    "    \n",
    "    state[\"actions\"] = actions\n",
    "    state[\"messages\"].append(f\"✓ Parsed actions\")\n",
    "    return state\n",
    "\n",
    "def update_playbook_node(state: ACEState) -> ACEState:\n",
    "    \"\"\"Node: Update the playbook based on curator decisions\"\"\"\n",
    "    playbook = state[\"playbook\"]\n",
    "    sections = state[\"sections\"]\n",
    "    actions = state[\"actions\"]\n",
    "    \n",
    "    updates_count = 0\n",
    "    \n",
    "    # Remove bullets\n",
    "    for idx in sorted(actions['bullets_to_remove'], reverse=True):\n",
    "        if playbook.remove_bullet(idx):\n",
    "            updates_count += 1\n",
    "    \n",
    "    # Update bullets\n",
    "    for insight_idx, bullet_idx in actions['insights_to_update'].items():\n",
    "        if 0 <= insight_idx - 1 < len(sections[\"INSIGHTS\"]):\n",
    "            insight_content = sections[\"INSIGHTS\"][insight_idx - 1]\n",
    "            if playbook.update_bullet(bullet_idx, insight_content):\n",
    "                updates_count += 1\n",
    "    \n",
    "    # Add bullets\n",
    "    for idx in actions['insights_to_add']:\n",
    "        if 0 <= idx - 1 < len(sections[\"INSIGHTS\"]):\n",
    "            insight_content = sections[\"INSIGHTS\"][idx - 1]\n",
    "            new_bullet = Bullet(content=insight_content)\n",
    "            playbook.add_bullet(new_bullet)\n",
    "            updates_count += 1\n",
    "    \n",
    "    # Add user profiles\n",
    "    for idx in actions['user_profiles_to_add']:\n",
    "        if 0 <= idx - 1 < len(sections[\"USER_PROFILE\"]):\n",
    "            profile_content = sections[\"USER_PROFILE\"][idx - 1]\n",
    "            playbook.modify_user_profile(\"default_user\", {f\"item_{idx}\": profile_content})\n",
    "            updates_count += 1\n",
    "    \n",
    "    # Update user profiles\n",
    "    for idx in actions['user_profiles_to_update']:\n",
    "        if 0 <= idx - 1 < len(sections[\"USER_PROFILE\"]):\n",
    "            profile_content = sections[\"USER_PROFILE\"][idx - 1]\n",
    "            playbook.modify_user_profile(\"default_user\", {f\"item_{idx}\": profile_content})\n",
    "            updates_count += 1\n",
    "    \n",
    "    # Update memories\n",
    "    for insight_idx, event_idx in actions['memories_events_to_update'].items():\n",
    "        if 0 <= insight_idx - 1 < len(sections[\"MEMORIES_EVENTS\"]):\n",
    "            event_content = sections[\"MEMORIES_EVENTS\"][insight_idx - 1]\n",
    "            if playbook.update_memory_event(event_idx, {\"event\": event_content}):\n",
    "                updates_count += 1\n",
    "    \n",
    "    # Add memories\n",
    "    for idx in actions['memories_events_to_add']:\n",
    "        if 0 <= idx - 1 < len(sections[\"MEMORIES_EVENTS\"]):\n",
    "            event_content = sections[\"MEMORIES_EVENTS\"][idx - 1]\n",
    "            playbook.add_memory_event({\"event\": event_content})\n",
    "            updates_count += 1\n",
    "    \n",
    "    state[\"messages\"].append(\n",
    "        f\"✓ Updated playbook: {len(playbook)} bullets, \"\n",
    "        f\"{len(playbook.user_profiles)} profiles, {len(playbook.memories_events)} events\"\n",
    "    )\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80959ac",
   "metadata": {},
   "source": [
    "## Build LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "397b7ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LangGraph workflow compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(ACEState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"retrieve_context\", retrieve_context_node)\n",
    "workflow.add_node(\"generate_answer\", generate_answer_node)\n",
    "workflow.add_node(\"reflect\", reflect_on_answer_node)\n",
    "workflow.add_node(\"parse_sections\", parse_sections_node)\n",
    "workflow.add_node(\"run_curators\", run_curators_node)\n",
    "workflow.add_node(\"parse_actions\", parse_actions_node)\n",
    "workflow.add_node(\"update_playbook\", update_playbook_node)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"retrieve_context\")\n",
    "workflow.add_edge(\"retrieve_context\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", \"reflect\")\n",
    "workflow.add_edge(\"reflect\", \"parse_sections\")\n",
    "workflow.add_edge(\"parse_sections\", \"run_curators\")\n",
    "workflow.add_edge(\"run_curators\", \"parse_actions\")\n",
    "workflow.add_edge(\"parse_actions\", \"update_playbook\")\n",
    "workflow.add_edge(\"update_playbook\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"✓ LangGraph workflow compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34f1c2",
   "metadata": {},
   "source": [
    "## Visualize the Graph (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f0f7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment to visualize (requires graphviz)\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33033ac4",
   "metadata": {},
   "source": [
    "## Run Single Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ad625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When did Caroline go to the LGBTQ support group?\n",
      "\n",
      "\n",
      "Workflow execution:\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Updated playbook: 4 bullets, 1 profiles, 2 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (1835 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 5 profiles, 9 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Updated playbook: 4 bullets, 1 profiles, 2 events\n",
      "\n",
      "================================================================================\n",
      "Playbook State:\n",
      "  Bullets: 4\n",
      "  User Profiles: 1\n",
      "  Memories/Events: 2\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize playbook\n",
    "playbook = Playbook()\n",
    "\n",
    "# Test with first question\n",
    "question = queries[0]['question']\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "# Create initial state\n",
    "initial_state = {\n",
    "    \"question\": question,\n",
    "    \"playbook\": playbook,\n",
    "    \"top_k\": 10,\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "# Run the graph\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "# Print messages\n",
    "print(\"\\nWorkflow execution:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(msg)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Playbook State:\")\n",
    "print(f\"  Bullets: {len(result['playbook'])}\")\n",
    "print(f\"  User Profiles: {len(result['playbook'].user_profiles)}\")\n",
    "print(f\"  Memories/Events: {len(result['playbook'].memories_events)}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca2535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Bullets:\n",
      "0. [ID: f80f550b] **Direct Answer Extraction:** The playbook should prioritize direct answer extraction when questions are factual and explicitly stated in the conversation. This is the most common type of question in this context. (✓0/✗0)\n",
      "1. [ID: 37a259df] **Handling Relative Time:** The playbook needs a mechanism to handle relative time references (e.g., \"yesterday,\" \"last week\"). Ideally, it would track the conversation's timeline to resolve these references. If that's not possible, acknowledging the relative nature of the answer is important. (✓0/✗0)\n",
      "2. [ID: 3de40834] **Contextual Awareness:** The playbook should be aware that the context is a series of conversational snippets, not a single document. This means information might be spread across multiple turns and require careful scanning. (✓0/✗0)\n",
      "3. [ID: a42c165c] **Identifying Key Entities:** Recognizing entities like \"LGBTQ support group,\" \"activist group,\" and specific group names (\"Connected LGBTQ Activists\") is crucial for accurate information retrieval. (✓0/✗0)\n",
      "\n",
      "User Profiles:\n",
      "User default_user: {'item_1': \"**Supportive and Encouraging:** Mel is consistently supportive and encouraging of Caroline's activism. This suggests a positive and empathetic communication style.\", 'item_2': '**Interested in Details:** Mel asks follow-up questions (\"Want to tell me a bit more about it?\") indicating a genuine interest in Caroline\\'s experiences.', 'item_3': '**Values Community and Acceptance:** Mel expresses values related to community, acceptance, and equality, as evidenced by comments like \"Reminds me it\\'s important to cultivate a loving and accepting environment.\"', 'item_5': '**Shares Personal Experiences:** Mel shares brief updates about her own life (\"took my kids to a park yesterday\"), indicating a willingness to reciprocate and build rapport.'}\n",
      "\n",
      "Memories and Events:\n",
      "0. {'event': '**Attending LGBTQ Support Group:** Caroline attended an LGBTQ support group \"yesterday\" (relative to the current conversation).'}\n",
      "1. {'event': '**Inspiration from Transgender Stories:** Caroline was inspired by transgender stories at the support group.'}\n"
     ]
    }
   ],
   "source": [
    "print(result['playbook'].format_for_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f2057",
   "metadata": {},
   "source": [
    "## Populate Codebook with Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "285cb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_codebook_langgraph(questions: List[str], initial_playbook: Playbook = None, top_k: int = 10) -> Playbook:\n",
    "    \"\"\"\n",
    "    Main function to populate a playbook using LangGraph\n",
    "    \n",
    "    Args:\n",
    "        questions: List of questions to process\n",
    "        initial_playbook: Starting playbook (creates new one if None)\n",
    "        top_k: Number of conversation chunks to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        Populated Playbook object\n",
    "    \"\"\"\n",
    "    if initial_playbook is None:\n",
    "        playbook = Playbook()\n",
    "    else:\n",
    "        playbook = initial_playbook\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Starting Playbook Population with {len(questions)} questions\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing Question {i}/{len(questions)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Q: {question}\\n\")\n",
    "        \n",
    "        # Create state for this question\n",
    "        state = {\n",
    "            \"question\": question,\n",
    "            \"playbook\": playbook,\n",
    "            \"top_k\": top_k,\n",
    "            \"messages\": []\n",
    "        }\n",
    "        \n",
    "        # Run the graph\n",
    "        result = app.invoke(state)\n",
    "        \n",
    "        # Print workflow execution\n",
    "        for msg in result[\"messages\"]:\n",
    "            print(msg)\n",
    "        \n",
    "        # Update playbook reference\n",
    "        playbook = result[\"playbook\"]\n",
    "        \n",
    "        print(f\"\\n📚 Playbook Status after Question {i}:\")\n",
    "        print(f\"   - Bullets: {len(playbook)}\")\n",
    "        print(f\"   - User Profiles: {len(playbook.user_profiles)}\")\n",
    "        print(f\"   - Memories/Events: {len(playbook.memories_events)}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Playbook Population Complete!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Final Statistics:\")\n",
    "    print(f\"   - Total Bullets: {len(playbook)}\")\n",
    "    print(f\"   - Total User Profiles: {len(playbook.user_profiles)}\")\n",
    "    print(f\"   - Total Memories/Events: {len(playbook.memories_events)}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return playbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1cad43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions available: 199\n",
      "\n",
      "First 5 questions:\n",
      "1. When did Caroline go to the LGBTQ support group?\n",
      "2. When did Melanie paint a sunrise?\n",
      "3. What fields would Caroline be likely to pursue in her educaton?\n",
      "4. What did Caroline research?\n",
      "5. What is Caroline's identity?\n"
     ]
    }
   ],
   "source": [
    "# Get question list\n",
    "question_list = [q['question'] for q in queries]\n",
    "print(f\"Total questions available: {len(question_list)}\")\n",
    "print(\"\\nFirst 5 questions:\")\n",
    "for i, q in enumerate(question_list[:5], 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c57b4756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Starting Playbook Population with 3 questions\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Question 1/3\n",
      "================================================================================\n",
      "Q: When did Caroline go to the LGBTQ support group?\n",
      "\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Updated playbook: 5 bullets, 1 profiles, 2 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Retrieved context (4555 chars)\n",
      "✓ Generated answer (2380 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 7 insights, 6 profiles, 8 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Updated playbook: 5 bullets, 1 profiles, 2 events\n",
      "\n",
      "📚 Playbook Status after Question 1:\n",
      "   - Bullets: 5\n",
      "   - User Profiles: 1\n",
      "   - Memories/Events: 2\n",
      "\n",
      "================================================================================\n",
      "Processing Question 2/3\n",
      "================================================================================\n",
      "Q: When did Melanie paint a sunrise?\n",
      "\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Updated playbook: 8 bullets, 1 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Retrieved context (4775 chars)\n",
      "✓ Generated answer (3770 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 5 insights, 6 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Updated playbook: 8 bullets, 1 profiles, 5 events\n",
      "\n",
      "📚 Playbook Status after Question 2:\n",
      "   - Bullets: 8\n",
      "   - User Profiles: 1\n",
      "   - Memories/Events: 5\n",
      "\n",
      "================================================================================\n",
      "Processing Question 3/3\n",
      "================================================================================\n",
      "Q: What fields would Caroline be likely to pursue in her educaton?\n",
      "\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Updated playbook: 9 bullets, 1 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Retrieved context (4694 chars)\n",
      "✓ Generated answer (5044 chars)\n",
      "✓ Reflection complete\n",
      "✓ Parsed sections: 2 insights, 10 profiles, 5 events\n",
      "✓ All curators completed\n",
      "✓ Parsed actions\n",
      "✓ Updated playbook: 9 bullets, 1 profiles, 5 events\n",
      "\n",
      "📚 Playbook Status after Question 3:\n",
      "   - Bullets: 9\n",
      "   - User Profiles: 1\n",
      "   - Memories/Events: 5\n",
      "\n",
      "================================================================================\n",
      "Playbook Population Complete!\n",
      "================================================================================\n",
      "Final Statistics:\n",
      "   - Total Bullets: 9\n",
      "   - Total User Profiles: 1\n",
      "   - Total Memories/Events: 5\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run on first 3 questions\n",
    "final_playbook = populate_codebook_langgraph(question_list[:3], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9c990",
   "metadata": {},
   "source": [
    "## Display Playbook Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d3b85c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PLAYBOOK SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📌 KNOWLEDGE BULLETS (9):\n",
      "--------------------------------------------------------------------------------\n",
      "0. **Successful Factual Recall:** The response successfully identified the relevant information about Caroline attending the LGBTQ support group. The strategy of scanning the conversation for keywords (\"LGBTQ support group,\" \"yesterday\") was effective.\n",
      "   [✓0/✗0]\n",
      "\n",
      "1. **Handling Relative Time:** The response correctly recognized \"yesterday\" as a relative term and acknowledged the need for a temporal anchor (\"last Tuesday\") to understand the timeframe.\n",
      "   [✓0/✗0]\n",
      "\n",
      "2. **Contextual Awareness:** The response demonstrated an understanding of the conversational flow and the importance of considering the preceding turns to interpret the meaning of \"yesterday.\"\n",
      "   [✓0/✗0]\n",
      "\n",
      "3. **Importance of Temporal Markers:** The conversation frequently uses temporal markers (e.g., \"yesterday,\" \"last Tuesday,\" \"last week\") which are crucial for understanding the sequence of events.\n",
      "   [✓0/✗0]\n",
      "\n",
      "4. **Topic Focus:** The conversation consistently revolves around LGBTQ+ rights, activism, community support, and personal experiences related to these topics.\n",
      "   [✓0/✗0]\n",
      "\n",
      "5. **Keyword Scanning is Effective, but Not Sufficient:** While keyword scanning for \"Melanie\" and \"paint\" helped identify relevant turns, it didn't directly lead to the answer (no sunrise painting). The negative result is important – it highlights the need to not just find mentions, but also *confirm* the absence of the target information.\n",
      "   [✓0/✗0]\n",
      "\n",
      "6. **Importance of Disambiguation:** The conversation features multiple creative activities (pottery, painting, drawing). The playbook needs to be able to distinguish between these activities and focus on the specific one requested.\n",
      "   [✓0/✗0]\n",
      "\n",
      "7. **Indirect Information is Valuable:** While Melanie didn't directly state she *didn't* paint a sunrise, the absence of such a statement, combined with her other activities, provides valuable information. The playbook should be able to infer information from what *isn't* said.\n",
      "   [✓0/✗0]\n",
      "\n",
      "8. **Combining Themes is Crucial:** The most successful aspect of the response was identifying the intersection of Caroline's passions – art and LGBTQ+ advocacy. This led to more nuanced and relevant field suggestions than focusing on either theme in isolation. The playbook should prioritize identifying combinations of interests.\n",
      "   [✓0/✗0]\n",
      "\n",
      "👤 USER PROFILES (1):\n",
      "--------------------------------------------------------------------------------\n",
      "User: default_user\n",
      "  - item_1: **Temporal Reasoning is Important:** The frequent use of relative time markers (\"yesterday,\" \"last week\") necessitates robust temporal reasoning capabilities. The playbook should be able to accurately interpret these markers and establish a clear timeline of events.\n",
      "  - item_2: **Event Sequencing Matters:** Understanding the order of events (Caroline joining the activist group *before* the conversation about the support group) provides valuable context. The playbook should track event sequences to improve its understanding of the conversational flow.\n",
      "  - item_3: **Indirect Communication:** Caroline doesn't explicitly state her educational goals. The playbook needs to be adept at inferring intentions and interests from subtle cues and patterns in the conversation.\n",
      "  - item_6: **Interested in Personal Stories:** Mel actively asks Caroline to elaborate on her experiences and motivations, suggesting a genuine interest in understanding Caroline's perspective.\n",
      "  - item_5: **Supportive & Encouraging:** Mel consistently offers positive feedback and expresses enthusiasm for Caroline's creative work, indicating a desire to foster a positive and encouraging environment.\n",
      "  - item_4: **Prioritize Actionable Fields:** Suggesting fields like \"Art Therapy\" is more actionable than simply \"Fine Arts.\" The playbook should aim to provide suggestions that are directly relevant to Caroline's expressed values and motivations.\n",
      "  - item_7: **Values Community & Acceptance:** Mel demonstrates a strong appreciation for community, acceptance, and the importance of platforms for marginalized groups, indicating a shared value system with Caroline.\n",
      "  - item_8: **Family-Oriented:** Mel mentions taking her kids to the park, suggesting family is important to her and could be a relevant topic for future conversations.\n",
      "  - item_9: **Creative & Artistic:** Mel engages in various creative pursuits and appreciates art in different forms, indicating a shared interest with Caroline.\n",
      "  - item_10: **Open to Sharing:** Mel willingly shares personal updates about her own activities, indicating a reciprocal conversational style and a willingness to build rapport.\n",
      "\n",
      "🎯 MEMORIES & EVENTS (5):\n",
      "--------------------------------------------------------------------------------\n",
      "0. {'event': '**Caroline joined a new LGBTQ activist group last Tuesday.** This is a key event that establishes a timeframe for subsequent conversations.'}\n",
      "\n",
      "1. {'event': '**Caroline attended an LGBTQ support group \"yesterday\" (relative to the current conversation).** This is the central event of the question.'}\n",
      "\n",
      "2. {'event': \"**Melanie made a plate in pottery class yesterday:** This provides context for Melanie's recent activities and helps differentiate them from painting.\"}\n",
      "\n",
      "3. {'event': '**Caroline is organizing an LGBTQ art show next month:** This is a future event that Mel is enthusiastic about and could be a topic for follow-up questions.'}\n",
      "\n",
      "4. {'event': '**Both Caroline and Melanie engage in nature-inspired art:** This shared interest could be leveraged for more engaging conversations.'}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_playbook_summary(playbook: Playbook):\n",
    "    \"\"\"Display a formatted summary of the playbook contents\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PLAYBOOK SUMMARY\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Display bullets\n",
    "    if playbook.bullets:\n",
    "        print(f\"📌 KNOWLEDGE BULLETS ({len(playbook.bullets)}):\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, bullet in enumerate(playbook.bullets):\n",
    "            print(f\"{i}. {bullet.content}\")\n",
    "            print(f\"   [✓{bullet.helpful_count}/✗{bullet.harmful_count}]\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"📌 KNOWLEDGE BULLETS: None\\n\")\n",
    "    \n",
    "    # Display user profiles\n",
    "    if playbook.user_profiles:\n",
    "        print(f\"👤 USER PROFILES ({len(playbook.user_profiles)}):\")\n",
    "        print(\"-\" * 80)\n",
    "        for user_id, profile in playbook.user_profiles.items():\n",
    "            print(f\"User: {user_id}\")\n",
    "            for key, value in profile.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"👤 USER PROFILES: None\\n\")\n",
    "    \n",
    "    # Display memories/events\n",
    "    if playbook.memories_events:\n",
    "        print(f\"🎯 MEMORIES & EVENTS ({len(playbook.memories_events)}):\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, event in enumerate(playbook.memories_events):\n",
    "            print(f\"{i}. {event}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"🎯 MEMORIES & EVENTS: None\\n\")\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Display the final playbook\n",
    "display_playbook_summary(final_playbook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
